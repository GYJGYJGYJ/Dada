{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method descriptions\n",
    "\n",
    "* **centralized** finds global classifier using the centralized data\n",
    "* Average local classifiers between neighbors\n",
    "  * **avg-unweighted** all the edges have the same value\n",
    "  * **avg-weighted** algorithm weights an edge as the *similarity* between the two nodes *times* the *number of instances* of the neighbor (normalized)\n",
    "* **regularised** learns local classifiers keeping them similar to the neighbors' classifiers\n",
    "* **local** learns independent local classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from evaluation import clf_variance, central_accuracy, central_loss, accuracies\n",
    "from network import line_network, synthetic_graph, true_theta_graph\n",
    "from optimization import centralized_FW, async_regularized_local_FW, regularized_local_FW, local_FW, global_regularized_local_FW\n",
    "from utils import generate_models, generate_moons\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set graph of nodes with local personalized data\n",
    "NB_ITER = 4000\n",
    "N = 100\n",
    "D = 20\n",
    "NOISE_R = 0.05\n",
    "random_state = 2017\n",
    "MU = 1\n",
    "\n",
    "V, theta_true, cluster_indexes = generate_models(nb_clust=1, nodes_per_clust=N, random_state=random_state)\n",
    "_, X, Y, X_test, Y_test, _, _ = generate_moons(V, theta_true, D, random_state=random_state, sample_error_rate=NOISE_R)\n",
    "\n",
    "# set graph\n",
    "nodes = synthetic_graph(X, Y, X_test, Y_test, V, theta_true)\n",
    "\n",
    "# set callbacks for optimization analysis\n",
    "callbacks = {\n",
    "    'accuracy': [central_accuracy, []],\n",
    "    'loss': [central_loss, []],\n",
    "    'clf-variance': [clf_variance, []]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "hist_accuracies = {}\n",
    "\n",
    "nodes_copy = deepcopy(nodes)\n",
    "results[\"centralized\"] = centralized_FW(nodes_copy, D, NB_ITER, callbacks=callbacks)\n",
    "hist_accuracies[\"centralized\"] = accuracies(nodes_copy)\n",
    "\n",
    "nodes_copy = deepcopy(nodes)\n",
    "results[\"regularized\"] = regularized_local_FW(nodes_copy, D, NB_ITER, mu=MU, callbacks=callbacks)\n",
    "hist_accuracies[\"regularized\"] = accuracies(nodes_copy)\n",
    "\n",
    "nodes_copy = deepcopy(nodes)\n",
    "results[\"async_regularized\"] = async_regularized_local_FW(nodes_copy, D, NB_ITER, mu=MU, callbacks=callbacks)\n",
    "hist_accuracies[\"async_regularized\"] = accuracies(nodes_copy)\n",
    "\n",
    "nodes_copy = deepcopy(nodes)\n",
    "results[\"local\"] = local_FW(nodes_copy, D, NB_ITER, callbacks=callbacks)\n",
    "hist_accuracies[\"local\"] = accuracies(nodes_copy)\n",
    "\n",
    "nodes_copy = deepcopy(nodes)\n",
    "results[\"global-reg\"] = global_regularized_local_FW(nodes_copy, D, NB_ITER, callbacks=callbacks)\n",
    "hist_accuracies[\"global-reg\"] = accuracies(nodes_copy)\n",
    "\n",
    "\n",
    "# get results with true thetas\n",
    "true_graph = true_theta_graph(nodes_copy, theta_true)\n",
    "acc = central_accuracy(true_graph)\n",
    "clf_var = clf_variance(true_graph)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4284140668>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(18, 10))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('train accuracy')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(len(r_list)), [r['accuracy'][0] for r in r_list], label='{}'.format(k))\n",
    "# add results of true thetas\n",
    "plt.plot(range(len(r_list)), [acc[0]]*len(r_list), label='true-theta')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('test accuracy')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(len(r_list)), [r['accuracy'][1] for r in r_list], label='{}'.format(k))\n",
    "plt.plot(range(len(r_list)), [acc[1]]*len(r_list), label='true-theta')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(len(r_list)), [r['loss'] for r in r_list], label='{}'.format(k))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('classifiers variance')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(len(r_list)), [r['clf-variance'] for r in r_list], label='{}'.format(k))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('duality gap')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(len(r_list)), [r['duality-gap'] for r in r_list], label='{}'.format(k))\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.suptitle(\"Histograms Train Accuracies\")\n",
    "plt.figure(2, figsize=(18, 10))\n",
    "\n",
    "for i, (k, r_list) in enumerate(hist_accuracies.items()):\n",
    "\n",
    "    plt.subplot(231 + i)\n",
    "    plt.title(k)\n",
    "    plt.ylim(0, N)\n",
    "    plt.hist(r_list[0], 10, range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.suptitle(\"Histograms Test Accuracies\")\n",
    "\n",
    "plt.figure(2, figsize=(18, 10))\n",
    "\n",
    "for i, (k, r_list) in enumerate(hist_accuracies.items()):\n",
    "\n",
    "    plt.subplot(231 + i)\n",
    "    plt.title(k)\n",
    "    plt.ylim(0, N)\n",
    "    plt.hist(r_list[1], 10, range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show first 20 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(18, 10))\n",
    "max_iter = 20\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('train accuracy')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(max_iter), [r['accuracy'][0] for r in r_list[:max_iter]], label='{}'.format(k))\n",
    "plt.plot(range(max_iter), [acc[0]]*max_iter, label='true-theta')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('test accuracy')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(max_iter), [r['accuracy'][1] for r in r_list[:max_iter]], label='{}'.format(k))\n",
    "plt.plot(range(max_iter), [acc[1]]*max_iter, label='true-theta')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(max_iter), [r['loss'] for r in r_list[:max_iter]], label='{}'.format(k))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.xlabel('nb iterations')\n",
    "plt.ylabel('clf variance')\n",
    "\n",
    "for k, r_list in results.items():\n",
    "    plt.plot(range(max_iter), [r['clf-variance'] for r in r_list[:max_iter]], label='{}'.format(k))\n",
    "plt.plot(range(max_iter), [clf_var]*max_iter, label='true-theta')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
